{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rtosVqJG10ov",
        "outputId": "fc5eebae-5d62-44a1-ff15-0517b642386d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install xgboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KsMV_rm94EYl",
        "outputId": "10c87e12-9fab-4ae8-91ac-20dd8b58ef35"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (3.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.0.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.21.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from xgboost) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lightgbm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OO0w_pPp4Y6W",
        "outputId": "8969b7f9-66a9-4958-fbde-2bce6ced3189"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.11/dist-packages (4.6.0)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from lightgbm) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from lightgbm) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost"
      ],
      "metadata": {
        "id": "biCebY5Z4V1X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce3b4bf1-a78f-4964-a62c-2f7f018b7d3f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.8-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from catboost) (0.21)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (3.2.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->catboost) (8.5.0)\n",
            "Downloading catboost-1.2.8-cp311-cp311-manylinux2014_x86_64.whl (99.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: catboost\n",
            "Successfully installed catboost-1.2.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import (\n",
        "    RandomForestClassifier, GradientBoostingClassifier, StackingClassifier,\n",
        "    AdaBoostClassifier, HistGradientBoostingClassifier\n",
        ")\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os"
      ],
      "metadata": {
        "id": "J4R-QAZ34mat"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load data\n",
        "data_path = r\"/content/drive/MyDrive/Datasets/wpbcA.csv\"\n",
        "data = pd.read_csv(data_path)\n",
        "\n",
        "# Encode target column\n",
        "data['outcome'] = data['outcome'].map({'R': 1, 'N': 0})\n",
        "\n",
        "# Drop unwanted columns\n",
        "columns_to_drop = ['id', 'time']\n",
        "data = data.drop(columns=columns_to_drop, errors='ignore')\n",
        "\n",
        "# Separate features and target\n",
        "X = data.drop('outcome', axis=1)\n",
        "y = data['outcome']\n",
        "\n",
        "# Drop columns with all NaNs and impute missing values\n",
        "X = X.dropna(axis=1, how='all')\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
        "\n",
        "# Feature selection: Select top 25 features\n",
        "selector = SelectKBest(score_func=mutual_info_classif, k=25)\n",
        "X_selected = selector.fit_transform(X, y)\n",
        "selected_features = X.columns[selector.get_support()]\n",
        "X = pd.DataFrame(X_selected, columns=selected_features)\n",
        "\n",
        "# Scaling\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X = pd.DataFrame(X_scaled, columns=selected_features)\n",
        "\n",
        "# Balance the dataset\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Fine-tuned classifiers\n",
        "models = {\n",
        "    \"GradientBoosting\": GradientBoostingClassifier(n_estimators=150, learning_rate=0.1, max_depth=3),\n",
        "    \"AdaBoost\": AdaBoostClassifier(n_estimators=100, learning_rate=0.8),\n",
        "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss', n_estimators=100, max_depth=4),\n",
        "    \"LightGBM\": LGBMClassifier(n_estimators=100, learning_rate=0.1),\n",
        "    \"CatBoost\": CatBoostClassifier(verbose=0, iterations=200, learning_rate=0.1, depth=4),\n",
        "    \"NaiveBayes\": GaussianNB(),\n",
        "    \"KNN\": KNeighborsClassifier(n_neighbors=5),\n",
        "    \"SVM\": SVC(probability=True, kernel='rbf', C=1.0, gamma='scale'),\n",
        "    \"LogisticRegression\": LogisticRegression(max_iter=1000, C=1.0),\n",
        "    \"DecisionTree\": DecisionTreeClassifier(max_depth=5),\n",
        "    \"RandomForest\": RandomForestClassifier(n_estimators=100, max_depth=5),\n",
        "    \"HistGradientBoosting\": HistGradientBoostingClassifier(max_iter=100)\n",
        "}\n",
        "\n",
        "# Add stacking classifier\n",
        "estimators = [\n",
        "    ('rf', RandomForestClassifier(n_estimators=100, max_depth=5)),\n",
        "    ('svc', SVC(probability=True, C=1.0, gamma='scale')),\n",
        "    ('xgb', XGBClassifier(eval_metric='logloss', n_estimators=100, max_depth=4))\n",
        "]\n",
        "models['Stacking'] = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\n",
        "\n",
        "# Evaluation setup\n",
        "results = {}\n",
        "metrics_list = []\n",
        "output_dir = r\"/content/drive/MyDrive/Datasets/WPBC results/With FS\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Training and evaluation loop\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    cr = classification_report(y_test, y_pred, output_dict=True)\n",
        "\n",
        "    TN, FP, FN, TP = cm.ravel()\n",
        "    sensitivity = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
        "    specificity = TN / (TN + FP) if (TN + FP) > 0 else 0\n",
        "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
        "    npv = TN / (TN + FN) if (TN + FN) > 0 else 0\n",
        "    f1 = 2 * (precision * sensitivity) / (precision + sensitivity) if (precision + sensitivity) > 0 else 0\n",
        "\n",
        "    metrics_list.append({\n",
        "        \"Model\": name,\n",
        "        \"Accuracy\": acc,\n",
        "        \"Sensitivity (Recall)\": sensitivity,\n",
        "        \"Specificity\": specificity,\n",
        "        \"Precision (PPV)\": precision,\n",
        "        \"NPV\": npv,\n",
        "        \"F1-Score\": f1\n",
        "    })\n",
        "\n",
        "    results[name] = {\n",
        "        \"accuracy\": acc,\n",
        "        \"classification_report\": cr,\n",
        "        \"confusion_matrix\": cm\n",
        "    }\n",
        "\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "    plt.title(f\"{name} Confusion Matrix\")\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"Actual\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(output_dir, f\"{name}_confusion_matrix.png\"))\n",
        "    plt.close()\n",
        "\n",
        "# Comparison plot\n",
        "model_names = [m[\"Model\"] for m in metrics_list]\n",
        "accuracies = [m[\"Accuracy\"] for m in metrics_list]\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=model_names, y=accuracies)\n",
        "plt.title(\"Model Accuracy Comparison (Scaled + Tuned)\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(output_dir, \"model_comparison.png\"))\n",
        "plt.close()\n",
        "\n",
        "# Save metrics\n",
        "metrics_df = pd.DataFrame(metrics_list).sort_values(by=\"Accuracy\", ascending=False)\n",
        "metrics_df.to_csv(os.path.join(output_dir, \"detailed_model_metrics.csv\"), index=False)\n",
        "\n",
        "print(f\"Results saved in: {output_dir}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Nqh2nPe2Tvu",
        "outputId": "6cf32108-3d6f-49f7-804a-7e600f482046"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [10:03:01] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 117, number of negative: 123\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000232 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1945\n",
            "[LightGBM] [Info] Number of data points in the train set: 240, number of used features: 25\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.487500 -> initscore=-0.050010\n",
            "[LightGBM] [Info] Start training from score -0.050010\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Results saved in: /content/drive/MyDrive/Datasets/WPBC results/With FS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, StackingClassifier, AdaBoostClassifier, HistGradientBoostingClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Load data\n",
        "data_path = r\"/content/drive/MyDrive/Datasets/wdbcA.csv\"\n",
        "data = pd.read_csv(data_path)\n",
        "\n",
        "# Drop ID column if exists\n",
        "data = data.drop(columns=['id'], errors='ignore')\n",
        "\n",
        "# Encode diagnosis column\n",
        "data['diagnosis'] = data['diagnosis'].map({'M': 1, 'B': 0})\n",
        "\n",
        "# Separate features and target\n",
        "X = data.drop('diagnosis', axis=1)\n",
        "y = data['diagnosis']\n",
        "\n",
        "# Drop columns with all missing values\n",
        "X = X.dropna(axis=1, how='all')\n",
        "X_columns_cleaned = X.columns\n",
        "\n",
        "# Impute missing values\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X = pd.DataFrame(imputer.fit_transform(X), columns=X_columns_cleaned)\n",
        "\n",
        "# Feature selection: top 25 features using ANOVA F-test\n",
        "selector = SelectKBest(score_func=f_classif, k=25)\n",
        "X = selector.fit_transform(X, y)\n",
        "\n",
        "# Normalize data using StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Balance the dataset using SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_scaled, y)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define models with default and tuned parameters (examples for a few)\n",
        "models = {\n",
        "    \"GradientBoosting\": GradientBoostingClassifier(n_estimators=200, learning_rate=0.05),\n",
        "    \"AdaBoost\": AdaBoostClassifier(n_estimators=100),\n",
        "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss', n_estimators=150, learning_rate=0.1),\n",
        "    \"LightGBM\": LGBMClassifier(n_estimators=150, learning_rate=0.1),\n",
        "    \"CatBoost\": CatBoostClassifier(verbose=0),\n",
        "    \"NaiveBayes\": GaussianNB(),\n",
        "    \"KNN\": KNeighborsClassifier(n_neighbors=7),\n",
        "    \"SVM\": SVC(probability=True, C=1.0, kernel='rbf'),\n",
        "    \"LogisticRegression\": LogisticRegression(max_iter=1000, C=1.0),\n",
        "    \"DecisionTree\": DecisionTreeClassifier(max_depth=5),\n",
        "    \"RandomForest\": RandomForestClassifier(n_estimators=150),\n",
        "    \"HistGradientBoosting\": HistGradientBoostingClassifier(max_iter=150)\n",
        "}\n",
        "\n",
        "# Add stacking classifier\n",
        "estimators = [\n",
        "    ('rf', RandomForestClassifier(n_estimators=100)),\n",
        "    ('svc', SVC(probability=True)),\n",
        "    ('xgb', XGBClassifier(eval_metric='logloss'))\n",
        "]\n",
        "models['Stacking'] = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\n",
        "\n",
        "# Prepare results\n",
        "results = {}\n",
        "metrics_list = []\n",
        "output_dir = r\"/content/drive/MyDrive/Datasets/WDBC results/With FS and Scaled\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Training loop\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    cr = classification_report(y_test, y_pred, output_dict=True)\n",
        "    TN, FP, FN, TP = cm.ravel()\n",
        "\n",
        "    sensitivity = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
        "    specificity = TN / (TN + FP) if (TN + FP) > 0 else 0\n",
        "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
        "    npv = TN / (TN + FN) if (TN + FN) > 0 else 0\n",
        "    f1 = 2 * (precision * sensitivity) / (precision + sensitivity) if (precision + sensitivity) > 0 else 0\n",
        "\n",
        "    metrics_list.append({\n",
        "        \"Model\": name,\n",
        "        \"Accuracy\": acc,\n",
        "        \"Sensitivity (Recall)\": sensitivity,\n",
        "        \"Specificity\": specificity,\n",
        "        \"Precision (PPV)\": precision,\n",
        "        \"NPV\": npv,\n",
        "        \"F1-Score\": f1\n",
        "    })\n",
        "\n",
        "    results[name] = {\"accuracy\": acc, \"classification_report\": cr}\n",
        "\n",
        "    # Save confusion matrix plot\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "    plt.title(f\"{name} Confusion Matrix\")\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"Actual\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(output_dir, f\"{name}_confusion_matrix.png\"))\n",
        "    plt.close()\n",
        "\n",
        "# Accuracy comparison plot\n",
        "model_names = [m[\"Model\"] for m in metrics_list]\n",
        "accuracies = [m[\"Accuracy\"] for m in metrics_list]\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=model_names, y=accuracies)\n",
        "plt.title(\"Model Accuracy Comparison\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(output_dir, \"model_comparison.png\"))\n",
        "plt.close()\n",
        "\n",
        "# Export metrics\n",
        "metrics_df = pd.DataFrame(metrics_list).sort_values(by=\"Accuracy\", ascending=False)\n",
        "metrics_df.to_csv(os.path.join(output_dir, \"detailed_model_metrics.csv\"), index=False)\n",
        "\n",
        "print(f\"Results saved in: {output_dir}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_NvwUZKJ3KGH",
        "outputId": "f0568c0a-f5fc-4531-c6f9-3cd2a0fd47d6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [10:03:50] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 283, number of negative: 288\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000290 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 4768\n",
            "[LightGBM] [Info] Number of data points in the train set: 571, number of used features: 25\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495622 -> initscore=-0.017514\n",
            "[LightGBM] [Info] Start training from score -0.017514\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results saved in: /content/drive/MyDrive/Datasets/WDBC results/With FS and Scaled\n"
          ]
        }
      ]
    }
  ]
}